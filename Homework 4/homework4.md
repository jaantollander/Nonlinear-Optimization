---
title: Nonlinear Programming - Homework 4
author: Jaan Tollander de Balsch - 452056
date: \today
bibliography: bibliography.bib
cls: https://raw.githubusercontent.com/citation-style-language/styles/master/harvard-anglia-ruskin-university.csl
# https://www.zotero.org/styles/frontiers-in-applied-mathematics-and-statistics
urlcolor: blue
header-includes: |
    \paperheight = 29.70 cm  \paperwidth = 21.0 cm  \hoffset        = 0.46 cm
    \headheight  =  0.81 cm  \textwidth  = 15.0 cm  \evensidemargin = 0.00 cm
    \headsep     =  0.81 cm  \textheight = 9.00 in  \oddsidemargin  = 0.00 cm
    \usepackage[font=small,labelfont=bf]{caption}
    \usepackage{setspace}
    \usepackage{booktabs}
    \allowdisplaybreaks
---
# Homework 4.1 FJ and KKT Conditions at Optimal Point
![Countour lines of the objective function (1), constraints (2-4) and the optimal point $\bar{x}=(1,0)$. \label{fig:1}](figures/4.1.svg)

## (a)
The feasible region and the optimal point $\bar{x}=(1, 0)$ are drawn in the figure \ref{fig:1}.

## (b)
From the optimization problem, we have
$$
\begin{aligned}
f(x) &= -x_1 \\
g_1(x) &= x_2 - (1-x_1)^3 \\
g_2(x) &= -x_1 \\
g_3(x) &= -x_2.
\end{aligned}
$$

The optimal point $\bar{x}$ is Fritz-Jones (FJ) point if there exists a nonzero $(u_0,u_1,u_2,u_3)$ and $u_i‚â•0$ such that
$$
u_0 ‚àáf(\bar{x}) + ‚àë_{i=1}^3 u_i ‚àág_i(\bar{x}) = ùüé.
$$

We can show that
$$
u_0 \left[\begin{matrix}-1\\0\end{matrix}\right] + 
u_1 \left[\begin{matrix}0\\1\end{matrix}\right] +
u_2 \left[\begin{matrix}-1\\0\end{matrix}\right] +
u_3 \left[\begin{matrix}0\\-1\end{matrix}\right]
= \left[\begin{matrix}0\\0\end{matrix}\right]
$$
is satisfied by values $(0, 1, 0, 1)$. Therefore, $\bar{x}$ satisfies Fritz-John (FJ) conditions.

## (c)
The KKT conditions are valid in $\bar{x}$ if there exists $(u_1,u_2,u_3)$ such that
$$
‚àáf(\bar{x}) + ‚àë_{i=1}^3 u_i ‚àág_i(\bar{x}) = ùüé.
$$

We can show that a solution to 
$$
\left[\begin{matrix}-1\\0\end{matrix}\right] + 
u_1 \left[\begin{matrix}0\\1\end{matrix}\right] +
u_2 \left[\begin{matrix}-1\\0\end{matrix}\right] +
u_3 \left[\begin{matrix}0\\-1\end{matrix}\right]
= \left[\begin{matrix}0\\0\end{matrix}\right]
$$
does not exist, because it would require $u_2=-1<0$. Therefore, the KKT conditions are not satisfied.

Linear independence CQ does not hold. Gradients $‚àág_1(\bar{x})$ and $‚àág_3(\bar{x})$ are not linearly independent.

Slater's CQ doesn't hold. Function $g_1$ is not convex.


\pagebreak

# Homework 4.2 KKT Conditions for a Quadratic Problem
![Countour lines of the objective function (5), constraints (6-9) and the optimal point $\bar{x}=(3/2,9/4)$. \label{fig:2}](figures/4.2.svg)

## (a)
From the optimization problem, we have
$$
\begin{aligned}
f(x) &= (x_1 - 9/4)^2 + (x_2 - 2)^2 \\
g_1(x) &= x_1^2 - x_2 \\
g_2(x) &= x_1 + x_2 - 6 \\
g_3(x) &= -x_1 \\
g_4(x) &= -x_2.
\end{aligned}
$$

The optimal point
$$
\bar{x} = (3/2, 9/4).
$$

The KKT condition hold if there exists $(u_1, u_2, u_3, u_4)$ such that
$$
‚àáf(\bar{x}) + ‚àë_{i=1}^4 u_i ‚àág_i(\bar{x}) = ùüé.
$$

We can derive a solution as follows.
$$
\left[\begin{matrix}- \frac{3}{2}\\ \frac{1}{2}\end{matrix}\right] + \  
u_1 \left[\begin{matrix}3\\-1\end{matrix}\right] + \  
u_2 \left[\begin{matrix}1\\-1\end{matrix}\right] + \  
u_3 \left[\begin{matrix}-1\\0\end{matrix}\right] + \  
u_4 \left[\begin{matrix}0\\-1\end{matrix}\right]
=
\left[\begin{matrix}3 u_{1} + u_{2} - u_{3} - \frac{3}{2}\\- u_{1} - u_{2} - u_{4} + \frac{1}{2}\end{matrix}\right] = \left[\begin{matrix}0\\0\end{matrix}\right].
$$
In another form we have
$$
\begin{cases}
u_3 = 3u_1 + u_2 - 3/2 ‚â• 0 \\
u_4 = u_1 + u_2 - 1/2 ‚â• 0
\end{cases}.
$$
By setting $u_3=0$ and $u_4=0$ we have
$$
\begin{cases}
u_3 = 3u_1 + u_2 - 3/2 = 0 \\
u_4 = u_1 + u_2 - 1/2 = 0
\end{cases},
$$
which has a solution $(u_1, u_2, u_3, u_4)=(1/2, 0, 0, 0)$. Therefore, the KKT conditions hold.

## (b)
The feasible region is drawn in the figure \ref{fig:2}. As can be seen, $-‚àáf$ is inside the cone spanned by the gradients $‚àág_1$ and $‚àág_2$, graphically verifying the KKT conditions.

## (c)
The point $\bar{x}$ is a unique global optimal because the function $f$ is convex and the constraints $g_1, g_2, g_3$ and $g_4$ are convex, that is, Slater's CQ holds.


# Homework 4.3 Lagrangian Dual of a Least-Squares Problem
## (a)
The Lagrangian dual of the least-squares problem is
$$
Œ∏(v) = \inf \{œï(v)‚à£x‚ààX\},
$$
where the Lagrangian function is
$$
œï(v) =x^T x + v^T (Ax-b)
$$
with decision variables $x‚ààùêë^n$, the problem data $A‚ààùêë^{m√ón}$ and $b‚ààùêë^m$ and the dual variables $v‚ààùêë^m$.

## (b)

$$
\begin{aligned}
Œ∏(v) &= \inf \{œï(v)‚à£x‚ààX\} \\
&= \inf \{x^T x + v^T (Ax-b)‚à£x‚ààX\} \\
&= \inf \{x^T x + v^TAx - v^Tb‚à£x‚ààX\} \\
...
\end{aligned}
$$

...

$$
\sup \{Œ∏(v)‚à£v‚â•0\}
$$


# Homework 4.4 Concavity of Lagrangian Dual Functions
The Lagrangian dual function is defined
$$
Œ∏(w) = \inf\{f(x)+w^T Œ≤(x) : x‚ààX\}
$$
where $w=(u,v)$ and $Œ≤=(g(x), h(x))$.

The function $Œ∏(w)$ is concave if the function $œï(w)=-Œ∏(w)$ is convex. Therefore, we need to show the convexity of the function
$$
œï(w)=\sup\{f(x)+w^T Œ≤(x) : x‚ààX\}.
$$

**Proof**: We have $Œª‚àà(0, 1)$ then
$$
\begin{aligned}
œï(Œªw_1 + (1-Œª)w_2) &= \sup\{f(x)+(Œªw_1 + (1-Œª)w_2)^T Œ≤(x) : x‚ààX\} \\
&= \sup\{f(x)+Œªw_1^TŒ≤(x) + (1-Œª)w_2^T Œ≤(x) : x‚ààX\} \\
&= \sup\{Œª(f(x)+w_1^TŒ≤(x)) + (1-Œª)(f(x)+w_2^T Œ≤(x)) : x‚ààX\} \\
&‚â§ \sup\{Œª(f(x)+w_1^TŒ≤(x)) : x‚ààX\} + \sup\{(1-Œª)(f(x)+w_2^T Œ≤(x)) : x‚ààX\} \\
&= Œª\sup\{f(x)+w_1^TŒ≤(x) : x‚ààX\} + (1-Œª)\sup\{f(x)+w_2^T Œ≤(x) : x‚ààX\} \\
&= Œª œï(w_1) + (1-Œª) œï(w_2).
\end{aligned}
$$


<!-- # References -->
